{"version":3,"file":"semconv.js","sourceRoot":"","sources":["../../src/semconv.ts"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;GAcG;;;AAEH;;;;GAIG;AAEH;;;;;;GAMG;AACU,QAAA,0BAA0B,GAAG,uBAAgC,CAAC;AAE3E;;;;;;GAMG;AACU,QAAA,8BAA8B,GACzC,2BAAoC,CAAC;AAEvC;;;;;;GAMG;AACU,QAAA,yBAAyB,GAAG,sBAA+B,CAAC;AAEzE;;;;;;GAMG;AACU,QAAA,kCAAkC,GAC7C,+BAAwC,CAAC;AAE3C;;;;;;GAMG;AACU,QAAA,+BAA+B,GAC1C,4BAAqC,CAAC;AAExC;;;;;;GAMG;AACU,QAAA,yBAAyB,GAAG,sBAA+B,CAAC;AAEzE;;;;;;;GAOG;AACU,QAAA,mCAAmC,GAC9C,gCAAyC,CAAC;AAE5C;;;;;;;;;;;;;;;;;;GAkBG;AACU,QAAA,kBAAkB,GAAG,eAAwB,CAAC;AAE3D;;;;;;;GAOG;AACU,QAAA,sBAAsB,GAAG,mBAA4B,CAAC;AAEnE;;;;;;GAMG;AACU,QAAA,8BAA8B,GACzC,2BAAoC,CAAC;AAEvC;;;;;;GAMG;AACU,QAAA,+BAA+B,GAC1C,4BAAqC,CAAC;AAExC;;GAEG;AACU,QAAA,gCAAgC,GAAG,MAAe,CAAC;AAEhE;;GAEG;AACU,QAAA,+BAA+B,GAAG,aAAsB,CAAC;AAEtE;;GAEG;AACU,QAAA,6BAA6B,GAAG,OAAgB,CAAC;AAE9D;;GAEG;AACU,QAAA,8BAA8B,GAAG,QAAiB,CAAC","sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/*\n * This file contains a copy of unstable semantic convention definitions\n * used by this package.\n * @see https://github.com/open-telemetry/opentelemetry-js/tree/main/semantic-conventions#unstable-semconv\n */\n\n/**\n * The name of the operation being performed.\n *\n * @note If one of the predefined values applies, but specific system uses a different name it's **RECOMMENDED** to document it in the semantic conventions for specific GenAI system and use system-specific name in the instrumentation. If a different name is not documented, instrumentation libraries **SHOULD** use applicable predefined value.\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_OPERATION_NAME = 'gen_ai.operation.name' as const;\n\n/**\n * The maximum number of tokens the model generates for a request.\n *\n * @example 100\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_REQUEST_MAX_TOKENS =\n  'gen_ai.request.max_tokens' as const;\n\n/**\n * The name of the GenAI model a request is being made to.\n *\n * @example \"gpt-4\"\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_REQUEST_MODEL = 'gen_ai.request.model' as const;\n\n/**\n * List of sequences that the model will use to stop generating further tokens.\n *\n * @example [\"forest\", \"lived\"]\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_REQUEST_STOP_SEQUENCES =\n  'gen_ai.request.stop_sequences' as const;\n\n/**\n * The temperature setting for the GenAI request.\n *\n * @example 0.0\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_REQUEST_TEMPERATURE =\n  'gen_ai.request.temperature' as const;\n\n/**\n * The top_p sampling setting for the GenAI request.\n *\n * @example 1.0\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_REQUEST_TOP_P = 'gen_ai.request.top_p' as const;\n\n/**\n * Array of reasons the model stopped generating tokens, corresponding to each generation received.\n *\n * @example [\"stop\"]\n * @example [\"stop\", \"length\"]\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_RESPONSE_FINISH_REASONS =\n  'gen_ai.response.finish_reasons' as const;\n\n/**\n * The Generative AI product as identified by the client or server instrumentation.\n *\n * @example \"openai\"\n *\n * @note The `gen_ai.system` describes a family of GenAI models with specific model identified\n * by `gen_ai.request.model` and `gen_ai.response.model` attributes.\n *\n * The actual GenAI product may differ from the one identified by the client.\n * Multiple systems, including Azure OpenAI and Gemini, are accessible by OpenAI client\n * libraries. In such cases, the `gen_ai.system` is set to `openai` based on the\n * instrumentation's best knowledge, instead of the actual system. The `server.address`\n * attribute may help identify the actual system in use for `openai`.\n *\n * For custom model, a custom friendly name **SHOULD** be used.\n * If none of these options apply, the `gen_ai.system` **SHOULD** be set to `_OTHER`.\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_SYSTEM = 'gen_ai.system' as const;\n\n/**\n * The type of token being counted.\n *\n * @example input\n * @example output\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_TOKEN_TYPE = 'gen_ai.token.type' as const;\n\n/**\n * The number of tokens used in the GenAI input (prompt).\n *\n * @example 100\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_USAGE_INPUT_TOKENS =\n  'gen_ai.usage.input_tokens' as const;\n\n/**\n * The number of tokens used in the GenAI response (completion).\n *\n * @example 180\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_GEN_AI_USAGE_OUTPUT_TOKENS =\n  'gen_ai.usage.output_tokens' as const;\n\n/**\n * Enum value \"chat\" for attribute {@link ATTR_GEN_AI_OPERATION_NAME}.\n */\nexport const GEN_AI_OPERATION_NAME_VALUE_CHAT = 'chat' as const;\n\n/**\n * Enum value \"aws.bedrock\" for attribute {@link ATTR_GEN_AI_SYSTEM}.\n */\nexport const GEN_AI_SYSTEM_VALUE_AWS_BEDROCK = 'aws.bedrock' as const;\n\n/**\n * Enum value \"input\" for attribute {@link ATTR_GEN_AI_TOKEN_TYPE}.\n */\nexport const GEN_AI_TOKEN_TYPE_VALUE_INPUT = 'input' as const;\n\n/**\n * Enum value \"output\" for attribute {@link ATTR_GEN_AI_TOKEN_TYPE}.\n */\nexport const GEN_AI_TOKEN_TYPE_VALUE_OUTPUT = 'output' as const;\n"]}