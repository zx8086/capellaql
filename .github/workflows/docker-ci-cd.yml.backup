# .github/workflows/docker-ci-cd.yml

name: Docker CI/CD with Bun and Snyk

on:
  push:
    branches: ["master"]
  pull_request:
    branches: ["master"]
  schedule:
    - cron: "0 0 * * 0"

env:
  BUILDKIT_STEP_LOG_MAX_SIZE: 10000000
  BUILDKIT_STEP_LOG_MAX_SPEED: 1000000
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1
  BUILDX_NO_DEFAULT_LOAD: true
  ACTIONS_CACHE_SIZE: 5GB
  ACTIONS_RUNTIME_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  ACTIONS_CACHE_DIR: /home/pi/.buildx-cache
  ACTIONS_RUNTIME_DIR: /home/pi/.buildx-runtime
  DOCKER_BUILDX_CACHE_DIR: /home/pi/.buildx-cache/docker
  GITHUB_WORKSPACE_CACHE: /home/pi/actions-runner/_work/_cache
  BUILDKIT_PROGRESS: plain

permissions:
  contents: read
  security-events: write
  packages: write

jobs:
  build-and-deploy:
    runs-on: self-hosted
    strategy:
      matrix:
        include:
          - platform: linux/amd64
            platform-name: amd64
          - platform: linux/arm64
            platform-name: arm64
      fail-fast: false
      max-parallel: 1

    steps:
      - uses: actions/checkout@v4

      - name: Setup Environment
        uses: ./.github/actions/setup-environment

      - name: Setup cache directories
        shell: bash
        run: |
          sudo mkdir -p ${{ env.ACTIONS_CACHE_DIR }}
          sudo mkdir -p ${{ env.ACTIONS_RUNTIME_DIR }}
          sudo mkdir -p ${{ env.DOCKER_BUILDX_CACHE_DIR }}
          sudo mkdir -p ${{ env.GITHUB_WORKSPACE_CACHE }}
          sudo chmod -R 777 ${{ env.ACTIONS_CACHE_DIR }}
          sudo chmod -R 777 ${{ env.ACTIONS_RUNTIME_DIR }}
          sudo chmod -R 777 ${{ env.DOCKER_BUILDX_CACHE_DIR }}
          sudo chmod -R 777 ${{ env.GITHUB_WORKSPACE_CACHE }}

          # Create cache key file if it doesn't exist
          echo "${GITHUB_SHA}" > ${{ env.ACTIONS_CACHE_DIR }}/cache-key

      - name: Cache BuildKit state
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.ACTIONS_CACHE_DIR }}
            ${{ env.DOCKER_BUILDX_CACHE_DIR }}
          key: buildx-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            buildx-${{ runner.os }}-
          enableCrossOsArchive: true

      - name: Create platform directories
        run: |
          PLATFORM_CACHE_DIR="${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}"
          mkdir -p "${PLATFORM_CACHE_DIR}/buildx"
          chmod -R 777 "${PLATFORM_CACHE_DIR}"

      - name: Verify platform cache directories
        run: |
          PLATFORM_CACHE_DIR="${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}"
          echo "Verifying cache directory for ${{ matrix.platform }}"
          if [ -d "${PLATFORM_CACHE_DIR}" ]; then
            ls -la "${PLATFORM_CACHE_DIR}"
            echo "Buildx cache contents:"
            ls -la "${PLATFORM_CACHE_DIR}/buildx" || echo "Buildx directory is empty"
          else
            echo "Creating platform cache directory"
            mkdir -p "${PLATFORM_CACHE_DIR}/buildx"
          fi

      - name: Setup platform-specific buildx configuration
        run: |
          PLATFORM_CACHE_DIR="${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}"
          mkdir -p "${PLATFORM_CACHE_DIR}/buildx"

          # Clean up any existing buildx resources
          docker buildx ls | grep builder- | awk '{print $1}' | xargs -r docker buildx rm -f || true
          docker ps -a | grep buildx_buildkit | awk '{print $1}' | xargs -r docker rm -f || true
          docker builder prune -f || true

          # Create buildx config file
          cat > buildkitd.toml << "EOF"
          [worker.oci]
          max-parallelism = 1
          gc = true

          [worker.containerd]
          gc = true
          gc-keepstorage = 5368709120

          [registry."docker.io"]
          mirrors = ["mirror.gcr.io"]

          [cache]
            [cache.local]
              type = "local"
              path = "${PLATFORM_CACHE_DIR}/buildx"
              max-size = 5368709120
            [cache.registry]
              type = "registry"
              ref = "docker.io/zx8086/capellaql:buildcache-${{ matrix.platform-name }}"
              max-size = 5368709120
          EOF

          # Create and initialize new builder
          BUILDER_NAME="builder-${{ matrix.platform-name }}"
          docker buildx create --bootstrap --use \
            --name "${BUILDER_NAME}" \
            --platform ${{ matrix.platform }} \
            --driver-opt network=host \
            --config "$(pwd)/buildkitd.toml" \
            --buildkitd-flags '--debug'

          # Verify builder is ready
          docker buildx inspect "${BUILDER_NAME}" --bootstrap

      - name: Cache npm/bun dependencies
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.GITHUB_WORKSPACE_CACHE }}/node_modules
            ${{ env.GITHUB_WORKSPACE_CACHE }}/bun
            ~/.bun/install/cache
            node_modules
            .build-cache
            dist
          key: ${{ runner.os }}-deps-${{ hashFiles('**/bun.lockb', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-

      - name: Move cache
        run: |
          if [ -d "${{ env.ACTIONS_CACHE_DIR }}" ]; then
            echo "Moving cache from previous build..."
            rm -rf ${{ env.ACTIONS_CACHE_DIR }}.tmp || true
            mv ${{ env.ACTIONS_CACHE_DIR }} ${{ env.ACTIONS_CACHE_DIR }}.tmp || true
            mkdir -p ${{ env.ACTIONS_CACHE_DIR }}
          fi

      - name: Warm up action cache
        shell: bash
        run: |
          # Restore cache from temp location if exists
          if [ -d "${{ env.ACTIONS_CACHE_DIR }}.tmp" ]; then
            echo "Restoring cache from temporary location..."
            cp -r ${{ env.ACTIONS_CACHE_DIR }}.tmp/* ${{ env.ACTIONS_CACHE_DIR }}/ || true
            rm -rf ${{ env.ACTIONS_CACHE_DIR }}.tmp
          fi

          # Touch all cache files to update access time
          find ${{ env.ACTIONS_CACHE_DIR }} -type f -exec touch {} +
          find ${{ env.DOCKER_BUILDX_CACHE_DIR }} -type f -exec touch {} +

      # Security tools installation (merged from capella-document-search)
      - name: Install verification tools
        shell: bash
        run: |
          # Create directories first
          mkdir -p "${GITHUB_WORKSPACE}/bin"
          mkdir -p "${GITHUB_WORKSPACE}/tmp"

          cd "${GITHUB_WORKSPACE}/tmp"

          # Install cosign
          curl -Lo cosign "https://github.com/sigstore/cosign/releases/latest/download/cosign-linux-amd64"
          chmod +x cosign
          mv cosign "${GITHUB_WORKSPACE}/bin/"

          # Install syft
          SYFT_RELEASE=$(curl -s https://api.github.com/repos/anchore/syft/releases/latest | grep -o '"tag_name": ".*"' | cut -d'"' -f4)
          curl -Lo syft.tar.gz "https://github.com/anchore/syft/releases/download/${SYFT_RELEASE}/syft_${SYFT_RELEASE#v}_linux_amd64.tar.gz"
          tar xzf syft.tar.gz syft
          mv syft "${GITHUB_WORKSPACE}/bin/"

          # Add to PATH
          echo "${GITHUB_WORKSPACE}/bin" >> $GITHUB_PATH

          # Cleanup
          cd "${GITHUB_WORKSPACE}"
          rm -rf "${GITHUB_WORKSPACE}/tmp"

          # Verify installations
          "${GITHUB_WORKSPACE}/bin/cosign" version || true
          "${GITHUB_WORKSPACE}/bin/syft" --version || true

      - name: Install additional security tools
        run: |
          # Install jq if not present
          if ! command -v jq &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

      # Initial Setup
      - name: Set build timestamp
        id: timestamp
        run: |
          echo "BUILD_TIMESTAMP=$(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> $GITHUB_ENV
          echo "BUILD_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Set platform name
        run: |
          PLATFORM_NAME=$(echo "${{ matrix.platform }}" | tr '/' '-')
          echo "PLATFORM_NAME=${PLATFORM_NAME}" >> $GITHUB_ENV

      - name: Create .env file
        run: |
          cat << EOF > .env
          ENABLE_FILE_LOGGING=${ENABLE_FILE_LOGGING:-false}
          ENABLE_OPENTELEMETRY=${ENABLE_OPENTELEMETRY:-false}
          BASE_URL=${{ vars.BASE_URL }}
          PORT=${{ vars.PORT }}
          LOG_LEVEL=${{ vars.LOG_LEVEL }}
          LOG_MAX_SIZE=${{ vars.LOG_MAX_SIZE }}
          LOG_MAX_FILES=${{ vars.LOG_MAX_FILES }}
          YOGA_RESPONSE_CACHE_TTL=${{ vars.YOGA_RESPONSE_CACHE_TTL }}
          COUCHBASE_URL=${{ secrets.COUCHBASE_URL }}
          COUCHBASE_USERNAME=${{ secrets.COUCHBASE_USERNAME }}
          COUCHBASE_PASSWORD=${{ secrets.COUCHBASE_PASSWORD }}
          COUCHBASE_BUCKET=${{ vars.COUCHBASE_BUCKET }}
          COUCHBASE_SCOPE=${{ vars.COUCHBASE_SCOPE }}
          COUCHBASE_COLLECTION=${{ vars.COUCHBASE_COLLECTION }}
          SERVICE_NAME=${{ vars.SERVICE_NAME }}
          SERVICE_VERSION=${{ vars.SERVICE_VERSION }}
          DEPLOYMENT_ENVIRONMENT=${{ vars.DEPLOYMENT_ENVIRONMENT }}
          TRACES_ENDPOINT=${{ vars.TRACES_ENDPOINT }}
          METRICS_ENDPOINT=${{ vars.METRICS_ENDPOINT }}
          LOGS_ENDPOINT=${{ vars.LOGS_ENDPOINT }}
          METRIC_READER_INTERVAL=${{ vars.METRIC_READER_INTERVAL }}
          CONSOLE_METRIC_READER_INTERVAL=${{ vars.CONSOLE_METRIC_READER_INTERVAL }}
          SUMMARY_LOG_INTERVAL=${{ vars.SUMMARY_LOG_INTERVAL }}
          ALLOWED_ORIGINS=${{ vars.ALLOWED_ORIGINS }}
          BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS=${{ vars.BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS }}
          SOURCE_MAP_SUPPORT=${{ vars.SOURCE_MAP_SUPPORT }}
          PRESERVE_SOURCE_MAPS=${{ vars.PRESERVE_SOURCE_MAPS }}
          EOF

      # Docker metadata setup (enhanced with capella-document-search labels)
      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: docker.io/zx8086/capellaql
          labels: |
            org.opencontainers.image.title=capellaql
            org.opencontainers.image.description=CapellaQL is a high-performance GraphQL service for Couchbase Capella databases
            org.opencontainers.image.version=${BUILD_VERSION}
            org.opencontainers.image.created=${BUILD_TIMESTAMP}
            org.opencontainers.image.revision=${GITHUB_SHA}
            org.opencontainers.image.authors=Simon Owusu <simonowusupvh@gmail.com>
            org.opencontainers.image.vendor=Siobytes
            org.opencontainers.image.licenses=MIT
            org.opencontainers.image.url=https://github.com/zx8086/capellaql
            org.opencontainers.image.source=https://github.com/zx8086/capellaql
            org.opencontainers.image.documentation=https://github.com/zx8086/capellaql/README.md
            org.opencontainers.image.base.name=oven/bun:canary-alpine
            org.opencontainers.image.source.repository=github.com/zx8086/capellaql
            org.opencontainers.image.source.branch=${GITHUB_REF_NAME:-master}
            org.opencontainers.image.source.commit=${GITHUB_SHA}
            com.capellaql.maintainer=Simon Owusu <simonowusupvh@gmail.com>
            com.capellaql.release-date=${BUILD_TIMESTAMP}
            com.capellaql.version.is-production=true
            org.opencontainers.image.ref.name=${GITHUB_REF_NAME:-master}
            org.opencontainers.image.version.semver=${GITHUB_REF_NAME:-2.0.0}
            org.opencontainers.image.version.major=2
            org.opencontainers.image.version.minor=0
            org.opencontainers.image.version.patch=0
          tags: |
            type=ref,event=branch
            type=sha,format=long
            type=raw,value=latest,enable={{is_default_branch}}
            type=schedule,pattern={{date 'YYYYMMDD'}}
            type=ref,event=tag
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=semver,pattern={{major}}
            type=sha,format=long
            type=raw,value=buildcache,enable=true

      - name: Cache Bun dependencies
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.ACTIONS_CACHE_DIR }}/bun
            ~/.bun/install/cache
            node_modules
            .build-cache
            dist
          key: ${{ runner.os }}-bun-${{ hashFiles('**/bun.lockb', '**/package.json', 'tsconfig.json') }}
          restore-keys: |
            ${{ runner.os }}-bun-${{ hashFiles('**/bun.lockb') }}-
            ${{ runner.os }}-bun-

      - name: Install dependencies and run post-install scripts
        run: |
          bun install
          bun pm untrusted || true
          bun pm trust --all || true

      # Security scanning section
      - name: Run Snyk code scan
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          export $(grep -v '^#' .env | xargs)
          bun run snyk test --file=package.json --sarif-file-output=snyk.sarif --severity-threshold=high
          bun run snyk monitor --file=package.json

      - name: Upload Snyk code scan results
        if: hashFiles('snyk.sarif') != ''
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: snyk.sarif
          category: snyk-code

      # Pre-build cleanup and cache warmup
      - name: Pre-build cleanup
        run: |
          docker system prune -a -f
          docker builder prune -a -f
        continue-on-error: true

      # Add the new cleanup step here, before the Docker build
      - name: Cleanup before build
        run: |
          docker buildx prune -f
          docker system prune -af
          rm -rf "${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}/buildx"
          mkdir -p "${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}/buildx"
          echo '{"layers":{}}' > "${ACTIONS_CACHE_DIR}/${{ matrix.platform-name }}/buildx/index.json"

      # Docker build and push section
      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_HUB_USERNAME }}
          password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}
          registry: docker.io

      - name: Prime BuildKit cache
        if: github.event_name != 'pull_request'
        uses: docker/build-push-action@v6
        with:
          context: .
          push: false
          load: false
          platforms: ${{ matrix.platform }}
          cache-from: |
            type=local,src=${{ env.DOCKER_BUILDX_CACHE_DIR }}
            type=registry,ref=docker.io/zx8086/capellaql:buildcache
            type=gha,scope=${{ github.workflow }}
          cache-to: |
            type=local,dest=/tmp/.buildx-cache,mode=max
            type=registry,ref=docker.io/zx8086/capellaql:buildcache,mode=max
            type=gha,mode=max,scope=${{ github.workflow }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        id: docker_build
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          platforms: ${{ matrix.platform }}
          builder: ${{ format('builder-{0}', matrix.platform-name) }}
          cache-from: |
            type=registry,ref=docker.io/zx8086/capellaql:buildcache-${{ matrix.platform-name }}
          cache-to: |
            type=registry,ref=docker.io/zx8086/capellaql:buildcache-${{ matrix.platform-name }},mode=max
          provenance: false
          sbom: true
          build-args: |
            BUILDKIT_INLINE_CACHE=1
            DOCKER_BUILDKIT=1
            BUILDKIT_PROGRESS=plain
            BUILD_DATE=${{ env.BUILD_TIMESTAMP }}
            BUILD_VERSION=${{ github.ref_name || '2.0.0' }}
            COMMIT_HASH=${{ github.sha }}
            GITHUB_REF_NAME=${{ github.ref_name }}
            NODE_ENV=production
            BASE_URL=${{ vars.BASE_URL }}
            PORT=${{ vars.PORT }}
            ENABLE_FILE_LOGGING=${{ vars.ENABLE_FILE_LOGGING }}
            ENABLE_OPENTELEMETRY=${{ vars.ENABLE_OPENTELEMETRY }}
            LOG_LEVEL=${{ vars.LOG_LEVEL }}
            LOG_MAX_SIZE=${{ vars.LOG_MAX_SIZE }}
            LOG_MAX_FILES=${{ vars.LOG_MAX_FILES }}
            YOGA_RESPONSE_CACHE_TTL=${{ vars.YOGA_RESPONSE_CACHE_TTL }}
            COUCHBASE_BUCKET=${{ vars.COUCHBASE_BUCKET }}
            COUCHBASE_SCOPE=${{ vars.COUCHBASE_SCOPE }}
            COUCHBASE_COLLECTION=${{ vars.COUCHBASE_COLLECTION }}
            SERVICE_NAME=${{ vars.SERVICE_NAME }}
            SERVICE_VERSION=${{ vars.SERVICE_VERSION }}
            DEPLOYMENT_ENVIRONMENT=${{ vars.DEPLOYMENT_ENVIRONMENT }}
            TRACES_ENDPOINT=${{ vars.TRACES_ENDPOINT }}
            METRICS_ENDPOINT=${{ vars.METRICS_ENDPOINT }}
            LOGS_ENDPOINT=${{ vars.LOGS_ENDPOINT }}
            METRIC_READER_INTERVAL=${{ vars.METRIC_READER_INTERVAL }}
            CONSOLE_METRIC_READER_INTERVAL=${{ vars.CONSOLE_METRIC_READER_INTERVAL }}
            SUMMARY_LOG_INTERVAL=${{ vars.SUMMARY_LOG_INTERVAL }}
            ALLOWED_ORIGINS=${{ vars.ALLOWED_ORIGINS }}
            BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS=${{ vars.BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS }}
            SOURCE_MAP_SUPPORT=true
            PRESERVE_SOURCE_MAPS=true

      # Add the new push step here, after the build
      - name: Push image with digest
        continue-on-error: true
        if: github.event_name != 'pull_request'
        run: |
          # Get the digest from the build step
          DIGEST="${{ steps.docker_build.outputs.digest }}"

          # Push the image with explicit digest
          docker buildx imagetools create \
            --tag docker.io/zx8086/capellaql:latest \
            --tag docker.io/zx8086/capellaql:${{ github.sha }} \
            docker.io/zx8086/capellaql@${DIGEST}

      - name: Verify build
        continue-on-error: true
        if: success()
        run: |
          echo "Verifying build for ${{ matrix.platform }}..."

          # Wait for image to be available
          sleep 15

          # Try to pull the image
          docker pull --platform ${{ matrix.platform }} docker.io/zx8086/capellaql:latest || true

          # Verify image exists
          if ! docker inspect docker.io/zx8086/capellaql:latest > /dev/null 2>&1; then
            echo "Warning: Image verification failed, but continuing..."
          else
            echo "‚úÖ Image verification successful"
          fi

          # Check platform-specific details
          docker inspect docker.io/zx8086/capellaql:latest | jq '.[0].Architecture'

      - name: Handle build failure
        continue-on-error: true
        if: failure()
        run: |
          echo "Build failed for ${{ matrix.platform }}"
          echo "Cleaning up..."
          docker system prune -af
          docker builder prune -af

          # Remove platform-specific cache
          rm -rf ${{ env.ACTIONS_CACHE_DIR }}/${{ matrix.platform-name }}

      # Add a platform-specific manifest creation step
      - name: Export digest
        continue-on-error: true
        if: success()
        run: |
          mkdir -p /tmp/digests
          digest="${{ steps.docker_build.outputs.digest }}"
          touch "/tmp/digests/${digest#sha256:}"

      # Create and push the manifest
      - name: Merge and push manifest
        continue-on-error: true
        if: success() && github.event_name != 'pull_request'
        run: |
          docker buildx imagetools create -t docker.io/zx8086/capellaql:latest \
            $(cat /tmp/digests/* | xargs -I {} echo "-t docker.io/zx8086/capellaql@{}")

      # Add platform-specific cache handling
      - name: Handle platform cache
        continue-on-error: true
        if: success()
        run: |
          CACHE_DIR="${{ env.ACTIONS_CACHE_DIR }}/${{ matrix.platform-name }}"
          mkdir -p "${CACHE_DIR}/chunks"

          if [ -f "${CACHE_DIR}/buildx-cache.tar.gz" ]; then
            cd "${CACHE_DIR}"
            split -b 1G buildx-cache.tar.gz "chunks/cache-chunk-"
          fi

      - name: Cache platform-specific chunks
        continue-on-error: true
        if: success()
        uses: actions/cache@v3
        with:
          path: ${{ env.ACTIONS_CACHE_DIR }}/${{ matrix.platform-name }}/chunks
          key: buildx-chunks-${{ runner.os }}-${{ matrix.platform-name }}-${{ github.sha }}
          restore-keys: |
            buildx-chunks-${{ runner.os }}-${{ matrix.platform-name }}-

      - name: Capture Build Output
        continue-on-error: true
        run: |
          echo "::group::Docker Build Output"
          docker buildx build \
            --progress=plain \
            --load \
            . 2>&1 | tee buildx.log
          echo "::endgroup::"

      - name: Process Build Log
        continue-on-error: true
        if: always()
        run: |
          if [ -f "buildx.log" ]; then
            echo "Processing build log..."
            # Extract cache information
            CACHE_HITS=$(grep -c "CACHED" buildx.log || echo "0")
            CACHE_MISSES=$(grep -c "DONE" buildx.log || echo "0")
            TOTAL_STEPS=$(grep -c "DONE\|CACHED" buildx.log || echo "0")

            # Calculate cache ratio
            if [ "$TOTAL_STEPS" -gt "0" ]; then
              CACHE_RATIO=$((CACHE_HITS * 100 / TOTAL_STEPS))
            else
              CACHE_RATIO=0
            fi

            echo "CACHE_HITS=${CACHE_HITS}" >> $GITHUB_ENV
            echo "CACHE_MISSES=${CACHE_MISSES}" >> $GITHUB_ENV
            echo "CACHE_RATIO=${CACHE_RATIO}" >> $GITHUB_ENV

            # Extract build duration
            BUILD_DURATION=$(grep "time=" buildx.log | tail -n1 | grep -oE 'time=[0-9]+\.[0-9]+' | cut -d= -f2)
            echo "BUILD_DURATION=${BUILD_DURATION}" >> $GITHUB_ENV

            # Save log summary
            echo "Build completed with ${CACHE_HITS} cache hits and ${CACHE_MISSES} cache misses"
            echo "Cache hit ratio: ${CACHE_RATIO}%"
            echo "Total build time: ${BUILD_DURATION}s"
          else
            echo "No build log file found"
          fi

      - name: Validate image metadata
        continue-on-error: true
        if: github.event_name != 'pull_request'
        run: |
          IMAGE_REF="docker.io/zx8086/capellaql:latest"

          echo "Validating image metadata..."
          docker buildx imagetools inspect ${IMAGE_REF} --format '{{json .}}' | jq .

          # Verify required labels
          REQUIRED_LABELS=(
            "org.opencontainers.image.title"
            "org.opencontainers.image.description"
            "org.opencontainers.image.version"
            "org.opencontainers.image.created"
            "org.opencontainers.image.authors"
            "org.opencontainers.image.vendor"
            "org.opencontainers.image.licenses"
          )

          for label in "${REQUIRED_LABELS[@]}"; do
            value=$(docker inspect ${IMAGE_REF} --format "{{ index .Config.Labels \"$label\" }}")
            if [ -z "$value" ]; then
              echo "‚ùå Missing required label: $label"
              exit 1
            else
              echo "‚úÖ Found label $label: $value"
            fi
          done

      - name: Verify image manifest
        if: github.event_name != 'pull_request'
        continue-on-error: true
        run: |
          # Wait for image to be available
          sleep 15

          # Check manifest with better error handling
          echo "Checking manifest..."
          MANIFEST=$(docker buildx imagetools inspect docker.io/zx8086/capellaql:latest --raw 2>/dev/null || echo '')

          if [ ! -z "$MANIFEST" ]; then
            echo "$MANIFEST" > manifest.json

            # Parse and validate manifest
            if jq -e . >/dev/null 2>&1 <<<"$MANIFEST"; then
              echo "‚úì Valid manifest structure found"

              # Check for specific manifest components
              ATTESTATIONS=$(jq -r '.manifests[].annotations."org.opencontainers.image.attestations"' manifest.json 2>/dev/null)
              if [ ! -z "$ATTESTATIONS" ] && [ "$ATTESTATIONS" != "null" ]; then
                echo "‚úì Attestations found in manifest"
              else
                echo "‚ö†Ô∏è No attestations found in manifest"
              fi
            else
              echo "‚ö†Ô∏è Invalid manifest structure"
            fi
          else
            echo "‚ö†Ô∏è Could not fetch manifest"
          fi

      - name: Verify image attestations
        if: github.event_name != 'pull_request'
        continue-on-error: true
        run: |
          echo "Checking attestations..."

          # Create directory for attestation results with unique timestamp
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          RESULTS_DIR="attestation-results-${TIMESTAMP}"
          mkdir -p "${RESULTS_DIR}"

          # Get image digest and reference
          echo "Getting image digest..."
          IMAGE_REF="docker.io/zx8086/capellaql:latest"
          IMAGE_DIGEST=$(docker buildx imagetools inspect "${IMAGE_REF}" --raw | jq -r '.manifests[0].digest')
          IMAGE_WITH_DIGEST="${IMAGE_REF}@${IMAGE_DIGEST}"

          echo "Image reference: ${IMAGE_REF}"
          echo "Image digest: ${IMAGE_DIGEST}"

          # Additional verification methods
          echo "Attempting direct verification..."
          cosign verify-attestation \
            --certificate-identity-regexp=".*" \
            --certificate-oidc-issuer="https://token.actions.githubusercontent.com" \
            "${IMAGE_WITH_DIGEST}" > "${RESULTS_DIR}/direct-attestation.json" 2>/dev/null || true

          echo "Attempting SLSA verification..."
          cosign verify-attestation \
            --type slsaprovenance \
            --certificate-identity-regexp=".*" \
            --certificate-oidc-issuer="https://token.actions.githubusercontent.com" \
            "${IMAGE_WITH_DIGEST}" > "${RESULTS_DIR}/slsa-attestation.json" 2>/dev/null || true

          echo "Attempting predicate-less verification..."
          cosign verify-attestation \
            --certificate-identity-regexp=".*" \
            --certificate-oidc-issuer="https://token.actions.githubusercontent.com" \
            "${IMAGE_WITH_DIGEST}" > "${RESULTS_DIR}/predicate-attestation.json" 2>/dev/null || true

          # Download all attestations for analysis
          echo "Downloading attestations..."
          cosign download attestation "${IMAGE_WITH_DIGEST}" > "${RESULTS_DIR}/all-attestations.json" 2>/dev/null || true

          # Extract from manifest and save all data
          echo "Extracting from manifest..."
          docker buildx imagetools inspect "${IMAGE_WITH_DIGEST}" --raw > "${RESULTS_DIR}/manifest.json"
          jq '.manifests[].annotations | select(."org.opencontainers.image.attestations" != null)' \
            "${RESULTS_DIR}/manifest.json" > "${RESULTS_DIR}/manifest-attestations.json" 2>/dev/null || true

          # Check results
          VERIFICATION_SUCCESS=false
          for file in "${RESULTS_DIR}"/*.json; do
            if [ -s "$file" ] && jq -e . >/dev/null 2>&1 < "$file"; then
              VERIFICATION_SUCCESS=true
              echo "‚úÖ Found valid data in $(basename "$file")"
            fi
          done

          # Generate comprehensive report
          {
            echo "### üìù Attestation Verification Report"
            echo "- Image: ${IMAGE_REF}"
            echo "- Digest: ${IMAGE_DIGEST}"
            echo "- Timestamp: $(date -u)"
            echo ""
            echo "#### Verification Results:"

            for file in "${RESULTS_DIR}"/*.json; do
              if [ -s "$file" ]; then
                basename=$(basename "$file")
                size=$(wc -c < "$file")
                echo "- File: ${basename}"
                echo "  - Size: ${size} bytes"
                if jq -e . >/dev/null 2>&1 < "$file"; then
                  echo "  - Status: ‚úÖ Valid JSON"
                  echo "  - Content Preview:"
                  jq -r 'try .predicateType // "No predicate type"' "$file" | head -n 1
                else
                  echo "  - Status: ‚ö†Ô∏è Invalid JSON"
                fi
              fi
            done

            echo ""
            echo "#### Overall Status:"
            if [ "$VERIFICATION_SUCCESS" = true ]; then
              echo "‚úÖ Successfully found attestation data"
            else
              echo "‚ö†Ô∏è No attestations could be verified"
            fi
          } > "${RESULTS_DIR}/verification-report.md"

          # Set output directory for next step
          echo "ATTESTATION_RESULTS_DIR=${RESULTS_DIR}" >> $GITHUB_ENV
          echo "VERIFICATION_SUCCESS=${VERIFICATION_SUCCESS}" >> $GITHUB_ENV

      - name: Upload attestation results
        if: github.event_name != 'pull_request'
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: attestation-results-${{ env.PLATFORM_NAME }}-${{ github.run_id }}
          path: ${{ env.ATTESTATION_RESULTS_DIR }}/
          retention-days: 90

      - name: Verify SBOM
        if: github.event_name != 'pull_request'
        continue-on-error: true
        run: |
          echo "Verifying SBOM..."

          # Create directory for SBOM files
          mkdir -p sbom-output

          # Generate SBOM using syft
          echo "Generating SBOM with syft..."
          if ! syft docker.io/zx8086/capellaql:latest \
            -o json=sbom-output/syft-sbom.json \
            -o spdx-json=sbom-output/spdx-sbom.json \
            -o cyclonedx-json=sbom-output/cyclonedx-sbom.json; then
            echo "‚ö†Ô∏è Failed to generate SBOM with syft, attempting alternative method..."
          else
            echo "‚úì Successfully generated SBOM files"
          fi

          # Validate generated SBOMs
          for sbom_file in sbom-output/*.json; do
            if [ -f "$sbom_file" ]; then
              echo "Validating $sbom_file..."
              if jq -e . >/dev/null 2>&1 <"$sbom_file"; then
                echo "‚úì Valid JSON structure in $sbom_file"
              else
                echo "‚ö†Ô∏è Invalid JSON structure in $sbom_file"
              fi
            fi
          done

          # Archive SBOM files if they exist
          if [ -d "sbom-output" ] && [ "$(ls -A sbom-output)" ]; then
            echo "Archiving SBOM files..."
            tar -czf sbom-files.tar.gz sbom-output/
            echo "‚úì SBOM files archived"
          fi

          # List generated files
          echo "Generated SBOM files:"
          ls -la sbom-output/

      - name: Upload SBOM Files
        if: github.event_name != 'pull_request' && success()
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: sbom-files-${{ env.PLATFORM_NAME }}
          path: |
            sbom-output/
            sbom-files.tar.gz
          retention-days: 90

      # Generate build record during build
      - name: Generate Docker Build Record
        continue-on-error: true
        if: success()
        run: |
          BUILD_RECORD_FILE="docker-build-records/zx8086-capellaql-${GITHUB_SHA::8}.dockerbuild"
          mkdir -p docker-build-records

          cat << EOF > "${BUILD_RECORD_FILE}"
          {
            "id": "${GITHUB_SHA}",
            "name": "capellaQL",
            "status": "completed",
            "cached": false,
            "duration": $(date +%s),
            "cache_metrics": {
              "hits": ${CACHE_HITS:-0},
              "misses": ${CACHE_MISSES:-0},
              "ratio": ${CACHE_RATIO:-0}
            },
            "build_inputs": {
              "build-args": {
                "NODE_ENV": "production",
                "BUILD_VERSION": "${GITHUB_REF_NAME:-0.0.1}",
                "COMMIT_HASH": "${GITHUB_SHA}",
                "BUILD_DATE": "${BUILD_TIMESTAMP}"
              },
              "context": ".",
              "platforms": ["linux/arm64", "linux/amd64"],
              "push": ${{ github.event_name != 'pull_request' }},
              "tags": ${{ toJSON(steps.meta.outputs.tags) }},
              "cache-from": ["type=registry,ref=zx8086/capellaql:buildcache"],
              "cache-to": ["type=registry,ref=zx8086/capellaql:buildcache,mode=max"]
            },
            "metadata": {
              "repository": "${GITHUB_REPOSITORY}",
              "workflow": "${GITHUB_WORKFLOW}",
              "run_id": "${GITHUB_RUN_ID}",
              "actor": "${GITHUB_ACTOR}",
              "ref": "${GITHUB_REF_NAME}",
              "sha": "${GITHUB_SHA}"
            }
          }
          EOF

      - name: Upload Build Record
        continue-on-error: true
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: docker-build-records-${{ env.PLATFORM_NAME }}
          path: docker-build-records/
          retention-days: 90

      # Testing section
      - name: Build local image for testing
        if: github.event_name != 'pull_request'
        uses: docker/build-push-action@v6
        with:
          context: .
          load: true
          tags: docker.io/zx8086/capellaql:latest
          platforms: ${{ matrix.platform }}
          cache-from: type=registry,ref=docker.io/zx8086/capellaql:buildcache
          build-args: |
            NODE_ENV=production
            BUILD_VERSION=${{ github.ref_name || '2.0.0' }}
            COMMIT_HASH=${{ github.sha }}
            BUILD_DATE=${{ env.BUILD_TIMESTAMP }}
            BASE_URL=${{ vars.BASE_URL }}
            PORT=${{ vars.PORT }}
            ENABLE_FILE_LOGGING=${{ vars.ENABLE_FILE_LOGGING }}
            ENABLE_OPENTELEMETRY=${{ vars.ENABLE_OPENTELEMETRY }}
            LOG_LEVEL=${{ vars.LOG_LEVEL }}
            LOG_MAX_SIZE=${{ vars.LOG_MAX_SIZE }}
            LOG_MAX_FILES=${{ vars.LOG_MAX_FILES }}
            YOGA_RESPONSE_CACHE_TTL=${{ vars.YOGA_RESPONSE_CACHE_TTL }}
            COUCHBASE_BUCKET=${{ vars.COUCHBASE_BUCKET }}
            COUCHBASE_SCOPE=${{ vars.COUCHBASE_SCOPE }}
            COUCHBASE_COLLECTION=${{ vars.COUCHBASE_COLLECTION }}
            SERVICE_NAME=${{ vars.SERVICE_NAME }}
            SERVICE_VERSION=${{ vars.SERVICE_VERSION }}
            DEPLOYMENT_ENVIRONMENT=${{ vars.DEPLOYMENT_ENVIRONMENT }}
            TRACES_ENDPOINT=${{ vars.TRACES_ENDPOINT }}
            METRICS_ENDPOINT=${{ vars.METRICS_ENDPOINT }}
            LOGS_ENDPOINT=${{ vars.LOGS_ENDPOINT }}
            METRIC_READER_INTERVAL=${{ vars.METRIC_READER_INTERVAL }}
            CONSOLE_METRIC_READER_INTERVAL=${{ vars.CONSOLE_METRIC_READER_INTERVAL }}
            SUMMARY_LOG_INTERVAL=${{ vars.SUMMARY_LOG_INTERVAL }}
            ALLOWED_ORIGINS=${{ vars.ALLOWED_ORIGINS }}
            BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS=${{ vars.BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS }}
            SOURCE_MAP_SUPPORT=true
            PRESERVE_SOURCE_MAPS=true

      - name: Test container (enhanced from capella-document-search)
        continue-on-error: true
        if: github.event_name != 'pull_request'
        run: |
          # Get the runner's architecture
          RUNNER_ARCH=$(uname -m)

          # Stop existing containers using port 4000
          docker ps -q --filter publish=4000 | xargs -r docker stop
          docker rm -f capellaql-test 2>/dev/null || true

          # Run new container with all necessary environment variables
          docker run -d \
            --name capellaql-test \
            -p 4000:4000 \
            --env-file .env \
            -e NODE_ENV=production \
            -e BUILD_VERSION=${{ github.ref_name || '2.0.0' }} \
            -e COMMIT_HASH=${{ github.sha }} \
            -e BUILD_DATE=${{ env.BUILD_TIMESTAMP }} \
            -e ENABLE_OPENTELEMETRY=false \
            -e ENABLE_FILE_LOGGING=false \
            -e LOG_MAX_FILES=7d \
            -e LOG_MAX_SIZE=10m \
            -e LOG_LEVEL=info \
            zx8086/capellaql:latest

          # Add delay and better error handling
          sleep 15
          if ! docker ps | grep -q capellaql-test; then
            echo "Container failed to start. Showing logs:"
            docker logs capellaql-test
            exit 1
          fi

          # Capture container metrics for summary
          CONTAINER_STATUS=$(docker inspect --format='{{.State.Status}}' capellaql-test)
          echo "CONTAINER_STATUS=${CONTAINER_STATUS}" >> $GITHUB_ENV
          echo "CONTAINER_START_TIME=$(docker inspect --format='{{.State.StartedAt}}' capellaql-test)" >> $GITHUB_ENV

          # Verify container health
          if [ "$CONTAINER_STATUS" != "running" ]; then
            echo "Container is not running. Status: $CONTAINER_STATUS"
            docker logs capellaql-test
            exit 1
          fi

          echo "‚úÖ Container test successful"

          echo "Container successfully started"

      - name: Inspect Docker image
        id: inspect
        run: |
          # Capture image details for summary
          echo "IMAGE_SIZE=$(docker image inspect zx8086/capellaql:latest --format='{{.Size}}')" >> $GITHUB_ENV
          echo "LAYER_COUNT=$(docker image inspect zx8086/capellaql:latest --format='{{len .RootFS.Layers}}')" >> $GITHUB_ENV

          docker image inspect zx8086/capellaql:latest
          docker history zx8086/capellaql:latest

      # Container security scanning
      - name: Run Snyk container scan
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          docker images
          snyk container test zx8086/capellaql:latest \
            --file=Dockerfile \
            --severity-threshold=high \
            --sarif-file-output=snyk-docker.sarif \
            --platform=linux/arm64 || true
          if [[ "${{ github.ref }}" == "refs/heads/master" ]]; then
            snyk container monitor zx8086/capellaql:latest \
              --file=Dockerfile \
              --platform=linux/arm64 || true
          fi

      - name: Upload Docker Snyk scan results
        if: always() && hashFiles('snyk-docker.sarif') != ''
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: snyk-docker.sarif
          category: snyk-docker

      - name: Set build end time
        run: echo "BUILD_END_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Cleanup old caches
        if: always()
        run: |
          # Keep only caches newer than 7 days
          find ${{ env.ACTIONS_CACHE_DIR }} -type f -atime +7 -delete
          find ${{ env.DOCKER_BUILDX_CACHE_DIR }} -type f -atime +7 -delete

          # Prune BuildKit cache but keep recent entries
          docker builder prune --filter until=168h --force --keep-storage=20GB

          # Remove temporary cache locations
          rm -rf ${{ env.ACTIONS_CACHE_DIR }}.tmp || true

      - name: Debug cache
        shell: bash
        run: |
          echo "Cache directory contents:"
          ls -la $ACTIONS_CACHE_DIR
          echo "Runtime directory contents:"
          ls -la $ACTIONS_RUNTIME_DIR
          echo "Actions directory contents:"
          ls -la ~/actions-runner/_work/_actions

      # Optimized Build Summary
      - name: Docker Build Summary
        continue-on-error: true
        if: always()
        run: |
          {
            # Header
            echo "### üê≥ Docker Build Summary"
            echo ""

            # Build Overview (combined metrics)
            echo "#### üìä Build Overview"
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| üÜî Build ID | \`${GITHUB_SHA::7}\` |"
            echo "| üì¶ Image | capellaQL |"
            echo "| ‚ö° Status | ${CONTAINER_STATUS:-N/A} |"
            echo "| ‚è±Ô∏è Duration | ${BUILD_DURATION:-N/A}s |"
            echo "| üíæ Cache Hits | ${CACHE_HITS:-0} |"
            echo "| üîÑ Cache Misses | ${CACHE_MISSES:-0} |"
            echo "| üìä Cache Ratio | ${CACHE_RATIO:-0}% |"
            echo "| üìö Total Layers | ${LAYER_COUNT:-N/A} |"
            echo "| üì¶ Image Size | $((${IMAGE_SIZE:-0}/1024/1024))MB |"

            # Cache Analysis (enhanced)
            echo ""
            echo "#### üîç Cache Performance"
            echo "\`\`\`"
            echo "Cache Hit Rate: ${CACHE_RATIO}%"
            echo "Layers Reused: ${CACHE_HITS}"
            echo "Layers Rebuilt: ${CACHE_MISSES}"
            echo "Cache Efficiency Score: $(( (CACHE_HITS * 100) / (CACHE_HITS + CACHE_MISSES) ))/100"
            echo "\`\`\`"

            # Build Performance (combined timing metrics)
            echo ""
            echo "#### üìà Build Performance"
            echo "\`\`\`"
            echo "Start Time: $(date -d @$BUILD_START_TIME +'%Y-%m-%d %H:%M:%S UTC')"
            echo "End Time: $(date -d @$BUILD_END_TIME +'%Y-%m-%d %H:%M:%S UTC')"
            echo "Duration: ${BUILD_DURATION}s"
            echo "Average Layer Build Time: $(( BUILD_DURATION / (CACHE_HITS + CACHE_MISSES) ))s"
            echo "\`\`\`"

            # Layer Analysis
            echo ""
            echo "#### üìö Layer Analysis"
            echo "\`\`\`"
            docker history zx8086/capellaql:latest --format "table {{.CreatedBy}}\t{{.Size}}\t{{.Comment}}" 2>/dev/null || echo "Layer history not available"
            echo "\`\`\`"

            # Resource Usage (if available)
            if docker stats --no-stream >/dev/null 2>&1; then
              echo ""
              echo "#### üîã Resource Usage"
              echo "\`\`\`"
              docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}\t{{.BlockIO}}" 2>/dev/null
              echo "\`\`\`"
            fi

            # Container Status (enhanced)
            echo ""
            echo "#### üê≥ Container Status"
            if [ "${CONTAINER_STATUS:-}" = "running" ]; then
              STATS=$(docker stats app-test --no-stream --format "{{.CPUPerc}},{{.MemUsage}},{{.NetIO}},{{.BlockIO}}")
              IFS=',' read -r CPU MEM NET BLOCK <<< "$STATS"
              echo "- Status: ‚úÖ Running"
              echo "- Start Time: ${CONTAINER_START_TIME}"
              echo "- CPU Usage: ${CPU}"
              echo "- Memory Usage: ${MEM}"
              echo "- Network I/O: ${NET}"
              echo "- Block I/O: ${BLOCK}"
            else
              echo "- Status: ‚ö†Ô∏è Not Running"
            fi

            # Security Scan Results (combined)
            echo ""
            echo "#### üîí Security Scan Results"
            if [ -f "snyk-docker.sarif" ]; then
              VULN_COUNT=$(grep -c "issue" snyk-docker.sarif || echo "0")
              CRITICAL_COUNT=$(grep -c '"level":"critical"' snyk-docker.sarif || echo "0")
              HIGH_COUNT=$(grep -c '"level":"high"' snyk-docker.sarif || echo "0")
              MEDIUM_COUNT=$(grep -c '"level":"medium"' snyk-docker.sarif || echo "0")
              LOW_COUNT=$(grep -c '"level":"low"' snyk-docker.sarif || echo "0")

              echo "##### üõ°Ô∏è Container Vulnerabilities"
              echo "- üíÄ Critical: ${CRITICAL_COUNT}"
              echo "- ‚ö†Ô∏è High: ${HIGH_COUNT}"
              echo "- ‚ö° Medium: ${MEDIUM_COUNT}"
              echo "- ‚ÑπÔ∏è Low: ${LOW_COUNT}"
              echo "- üìä Total: ${VULN_COUNT}"
            fi

            # Code Vulnerabilities
            if [ -f "snyk.sarif" ]; then
              CODE_VULN_COUNT=$(grep -c "issue" snyk.sarif || echo "0")
              CODE_CRITICAL_COUNT=$(grep -c '"level":"critical"' snyk.sarif || echo "0")
              CODE_HIGH_COUNT=$(grep -c '"level":"high"' snyk.sarif || echo "0")
              CODE_MEDIUM_COUNT=$(grep -c '"level":"medium"' snyk.sarif || echo "0")
              CODE_LOW_COUNT=$(grep -c '"level":"low"' snyk.sarif || echo "0")

              echo ""
              echo "##### üîç Code Vulnerabilities"
              echo "- üíÄ Critical: ${CODE_CRITICAL_COUNT}"
              echo "- ‚ö†Ô∏è High: ${CODE_HIGH_COUNT}"
              echo "- ‚ö° Medium: ${CODE_MEDIUM_COUNT}"
              echo "- ‚ÑπÔ∏è Low: ${CODE_LOW_COUNT}"
              echo "- üìä Total: ${CODE_VULN_COUNT}"
            fi

            # Environment Information
            echo ""
            echo "#### üåç Environment Details"
            echo "- üî∞ Node Environment: production"
            echo "- üìç Deployment: ${DEPLOYMENT_ENVIRONMENT:-development}"
            echo "- üåê Base URL: ${BASE_URL:-http://localhost}"
            echo "- üö™ Port: ${PORT:-4000}"
            echo "- üìù Log Level: ${LOG_LEVEL:-info}"
            echo "- üîÑ OpenTelemetry: ${ENABLE_OPENTELEMETRY:-false}"
            echo "- üìä File Logging: ${ENABLE_FILE_LOGGING:-false}"

            # Build Configuration
            echo ""
            echo "#### ‚öôÔ∏è Build Configuration"
            echo "- üìã Version: ${{ github.ref_name || '0.0.1' }}"
            echo "- üîÑ Commit: ${GITHUB_SHA}"
            echo "- üìÖ Date: ${BUILD_TIMESTAMP}"
            echo "- üõ†Ô∏è Workflow: ${GITHUB_WORKFLOW}"
            echo "- üë§ Actor: ${GITHUB_ACTOR}"
            echo "- üåø Branch: ${GITHUB_REF_NAME}"

            # Build Artifacts
            echo ""
            echo "#### üì¶ Artifacts"
            echo "- Build Record: \`docker-build-records/zx8086-capellaql-${GITHUB_SHA::8}.dockerbuild\`"
            echo "- SBOM: Available in image attestations"
            echo "- Provenance: Included in image metadata"

            # Optimization Recommendations
            echo ""
            echo "#### üí° Build Optimization Recommendations"
            if [ $CACHE_RATIO -lt 50 ]; then
              echo "‚ö†Ô∏è Low cache hit ratio detected. Consider:"
              echo "- Reviewing Dockerfile layer ordering"
              echo "- Implementing better cache strategies"
              echo "- Checking for unnecessary cache invalidation"
            else
              echo "‚úÖ Build cache is performing well with ${CACHE_RATIO}% hit rate"
            fi
          } >> $GITHUB_STEP_SUMMARY

      - name: Cleanup and maintain cache
        run: |
          # Remove old cache entries
          find ${{ env.ACTIONS_CACHE_DIR }} -type f -mtime +7 -delete
          find ${{ env.DOCKER_BUILDX_CACHE_DIR }} -type f -mtime +7 -delete

          # Compress remaining cache
          if [ -d "${{ env.DOCKER_BUILDX_CACHE_DIR }}" ]; then
            cd ${{ env.DOCKER_BUILDX_CACHE_DIR }}
            tar czf ../buildx-cache.tar.gz .
            cd ..
            rm -rf ${{ env.DOCKER_BUILDX_CACHE_DIR }}
            mkdir -p ${{ env.DOCKER_BUILDX_CACHE_DIR }}
            tar xzf buildx-cache.tar.gz -C ${{ env.DOCKER_BUILDX_CACHE_DIR }}
            rm buildx-cache.tar.gz
          fi

      # Build Summary (merged from capella-document-search)
      - name: Docker Build Summary
        if: always()
        run: |
          {
            echo "### üê≥ Docker Build Summary"
            echo ""
            echo "#### üìä Build Overview"
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| üÜî Build ID | \`${GITHUB_SHA::7}\` |"
            echo "| üì¶ Image | capellaql |"
            echo "| üèóÔ∏è Platform | ${{ matrix.platform }} |"
            echo "| ‚ö° Status | ${CONTAINER_STATUS:-N/A} |"

            # Container Status
            if [ "${CONTAINER_STATUS:-}" = "running" ]; then
              STATS=$(docker stats capellaql-test --no-stream --format "{{.CPUPerc}},{{.MemUsage}},{{.NetIO}},{{.BlockIO}}" 2>/dev/null || echo "N/A,N/A,N/A,N/A")
              echo "| üîÑ Status | ‚úÖ Running |"
              echo "| üïí Start Time | ${CONTAINER_START_TIME} |"
              echo "| üìà Cache Ratio | ${CACHE_RATIO:-0}% |"
              echo "| ‚è±Ô∏è Build Duration | ${BUILD_DURATION:-N/A}s |"
            else
              echo "| üîÑ Status | ‚ö†Ô∏è Not Running |"
            fi

            echo ""
            echo "#### üîí Security Features"
            echo "- ‚úÖ SBOM Generation"
            echo "- ‚úÖ Container Attestations"
            echo "- ‚úÖ Snyk Security Scanning"
            echo "- ‚úÖ Multi-platform Build"
          } >> $GITHUB_STEP_SUMMARY

      # Enhanced cleanup with workspace cleaning (merged from capella-document-search)
      - name: Cleanup
        if: always()
        continue-on-error: true
        run: |
          rm -f .env .env.production
          rm -f snyk.sarif snyk-docker.sarif
          docker container rm -f capellaql-test || true
          docker image prune -f
          docker volume prune -f
          docker builder prune -a -f
          rm -rf security-artifacts
          rm -rf "${GITHUB_WORKSPACE}/bin/syft"
          rm -rf "${GITHUB_WORKSPACE}/bin/cosign"
          rm -rf ~/.sigstore
          rm -rf node_modules
          rm -rf .gradle
          rm -rf build
          echo "Cleanup completed"
